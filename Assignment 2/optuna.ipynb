{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization with Optuna library\n",
    "\n",
    "This notebook serves the purpose of finding a good hyperparameter configuration for our matrix factorization approach. We will use Optuna for hyperparameter optimization to improve the performance of our recommendation system. The notebook includes data loading, preprocessing, model training, evaluation, and submission preparation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # For CUDA\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set the seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7260</td>\n",
       "      <td>20145</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>243238</td>\n",
       "      <td>85182</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9135</td>\n",
       "      <td>45973</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18671</td>\n",
       "      <td>63554</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>243293</td>\n",
       "      <td>81002</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  user_id  rating\n",
       "0     7260    20145     3.5\n",
       "1   243238    85182     4.0\n",
       "2     9135    45973     1.0\n",
       "3    18671    63554     3.0\n",
       "4   243293    81002     5.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3786</td>\n",
       "      <td>40484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1985</td>\n",
       "      <td>47039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2290</td>\n",
       "      <td>60111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>118657</td>\n",
       "      <td>64447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1560</td>\n",
       "      <td>2953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  book_id  user_id\n",
       "0   0     3786    40484\n",
       "1   1     1985    47039\n",
       "2   2     2290    60111\n",
       "3   3   118657    64447\n",
       "4   4     1560     2953"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Books Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>book_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0440234743</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0452264464</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN  book_id\n",
       "0  0002005018        1\n",
       "1  0374157065        3\n",
       "2  0399135782        5\n",
       "3  0440234743       18\n",
       "4  0452264464       19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = 'data/'\n",
    "\n",
    "train_df = pd.read_csv(f'{data_dir}train.csv')\n",
    "test_df = pd.read_csv(f'{data_dir}test.csv')\n",
    "books_df = pd.read_csv(f'{data_dir}books.csv')\n",
    "\n",
    "# Display first few rows of each DataFrame\n",
    "print(\"Train Data:\")\n",
    "display(train_df.head())\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "display(test_df.head())\n",
    "\n",
    "print(\"\\nBooks Data:\")\n",
    "display(books_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping users and books to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 18906\n",
      "Number of unique books: 15713\n"
     ]
    }
   ],
   "source": [
    "# Get unique user_ids and book_ids from training data\n",
    "unique_users = train_df['user_id'].unique()\n",
    "unique_books = train_df['book_id'].unique()\n",
    "\n",
    "# Create mappings\n",
    "user2idx = {user_id: idx for idx, user_id in enumerate(unique_users)}\n",
    "book2idx = {book_id: idx for idx, book_id in enumerate(unique_books)}\n",
    "\n",
    "# Apply mappings to train and test data\n",
    "train_df['user_idx'] = train_df['user_id'].map(user2idx)\n",
    "train_df['book_idx'] = train_df['book_id'].map(book2idx)\n",
    "\n",
    "test_df['user_idx'] = test_df['user_id'].map(user2idx)\n",
    "test_df['book_idx'] = test_df['book_id'].map(book2idx)\n",
    "\n",
    "# Handle users/books in test set not seen in training\n",
    "# Assign a special index for unknown users/books\n",
    "unknown_user_idx = len(user2idx)\n",
    "unknown_book_idx = len(book2idx)\n",
    "\n",
    "test_df['user_idx'] = test_df['user_idx'].fillna(unknown_user_idx).astype(int)\n",
    "test_df['book_idx'] = test_df['book_idx'].fillna(unknown_book_idx).astype(int)\n",
    "\n",
    "# Update mappings to include unknown user and book\n",
    "if unknown_user_idx not in user2idx.values():\n",
    "    user2idx['unknown'] = unknown_user_idx\n",
    "\n",
    "if unknown_book_idx not in book2idx.values():\n",
    "    book2idx['unknown'] = unknown_book_idx\n",
    "\n",
    "print(f\"Number of unique users: {len(user2idx)}\")\n",
    "print(f\"Number of unique books: {len(book2idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: 90470\n",
      "Validation Set Size: 10053\n"
     ]
    }
   ],
   "source": [
    "# Split the original training data into training and validation sets\n",
    "train_data, val_data = train_test_split(train_df, test_size=0.1, random_state=42)\n",
    "\n",
    "print(f\"Training Set Size: {len(train_data)}\")\n",
    "print(f\"Validation Set Size: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRatingsDataset(Dataset):\n",
    "    def __init__(self, dataframe, is_train=True):\n",
    "        self.is_train = is_train\n",
    "        self.user = torch.tensor(dataframe['user_idx'].values, dtype=torch.long)\n",
    "        self.book = torch.tensor(dataframe['book_idx'].values, dtype=torch.long)\n",
    "        if self.is_train:\n",
    "            self.rating = torch.tensor(dataframe['rating'].values, dtype=torch.float32)\n",
    "        else:\n",
    "            self.id = torch.tensor(dataframe['id'].values, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            return self.user[idx], self.book[idx], self.rating[idx]\n",
    "        else:\n",
    "            return self.id[idx], self.user[idx], self.book[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define default batch size\n",
    "default_batch_size = 1024  # This will be optimized later\n",
    "\n",
    "# Create Dataset objects\n",
    "train_dataset = BookRatingsDataset(train_data, is_train=True)\n",
    "val_dataset = BookRatingsDataset(val_data, is_train=True)\n",
    "test_dataset = BookRatingsDataset(test_df, is_train=False)\n",
    "\n",
    "# Create DataLoaders with num_workers=0\n",
    "train_loader = DataLoader(train_dataset, batch_size=default_batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=default_batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=default_batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(nn.Module):\n",
    "    def __init__(self, num_users, num_books, embedding_size=100, dropout_rate=0.1):\n",
    "        super(MatrixFactorization, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.book_embedding = nn.Embedding(num_books, embedding_size)\n",
    "        self.user_bias = nn.Embedding(num_users, 1)\n",
    "        self.book_bias = nn.Embedding(num_books, 1)\n",
    "        self.global_bias = nn.Parameter(torch.tensor([3.0]))\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.normal_(self.user_embedding.weight, mean=0, std=0.1)\n",
    "        nn.init.normal_(self.book_embedding.weight, mean=0, std=0.1)\n",
    "        nn.init.constant_(self.user_bias.weight, 0.0)\n",
    "        nn.init.constant_(self.book_bias.weight, 0.0)\n",
    "\n",
    "    def forward(self, user, book):\n",
    "        user_emb = self.user_embedding(user)\n",
    "        book_emb = self.book_embedding(book)\n",
    "        user_b = self.user_bias(user).squeeze()\n",
    "        book_b = self.book_bias(book).squeeze()\n",
    "        dot = (user_emb * book_emb).sum(1)\n",
    "        pred = dot + user_b + book_b + self.global_bias\n",
    "        pred = self.activation(pred)\n",
    "        pred = self.dropout(pred) * 4.0 + 1.0  # Scale to [1.0, 5.0]\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixFactorization(\n",
      "  (user_embedding): Embedding(18906, 100)\n",
      "  (book_embedding): Embedding(15713, 100)\n",
      "  (user_bias): Embedding(18906, 1)\n",
      "  (book_bias): Embedding(15713, 1)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (activation): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "num_users = len(user2idx)\n",
    "num_books = len(book2idx)\n",
    "embedding_size = 100\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# Initialize the model\n",
    "model = MatrixFactorization(num_users, num_books, embedding_size, dropout_rate)\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "patience = 10  # Number of epochs to wait for improvement before stopping\n",
    "\n",
    "# Define loss function and optimizer with L2 regularization (weight_decay)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# Initialize variables for Early Stopping\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# Initialize a list to store the last 5 log messages\n",
    "recent_logs = []\n",
    "max_logs = 5  # Maximum number of logs to display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: Train Loss = 0.3429, Validation Loss = 0.7633\n",
      "Epoch 97: Train Loss = 0.3366, Validation Loss = 0.7622\n",
      "Epoch 98: Train Loss = 0.3385, Validation Loss = 0.7609\n",
      "Epoch 99: Train Loss = 0.3505, Validation Loss = 0.7601\n",
      "Epoch 100: Train Loss = 0.3497, Validation Loss = 0.7592\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for user, book, rating in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs} - Training\"):\n",
    "        user = user.to(device)\n",
    "        book = book.to(device)\n",
    "        rating = rating.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(user, book)\n",
    "        loss = criterion(outputs, rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for user, book, rating in tqdm(val_loader, desc=f\"Epoch {epoch}/{epochs} - Validation\"):\n",
    "            user = user.to(device)\n",
    "            book = book.to(device)\n",
    "            rating = rating.to(device)\n",
    "\n",
    "            outputs = model(user, book)\n",
    "            loss = criterion(outputs, rating)\n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "\n",
    "    # Logging\n",
    "    log_message = f\"Epoch {epoch}: Train Loss = {avg_train_loss:.4f}, Validation Loss = {avg_val_loss:.4f}\"\n",
    "    recent_logs.append(log_message)\n",
    "    if len(recent_logs) > max_logs:\n",
    "        recent_logs.pop(0)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(\"\\n\".join(recent_logs))\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    emb_size = trial.suggest_int('embedding_size', 75, 200, step=1)\n",
    "    lr = trial.suggest_loguniform('learning_rate', 1e-4, 1e-2)\n",
    "    batch_size = trial.suggest_int('batch_size', 512, 2048, step=128)\n",
    "\n",
    "    # Create DataLoaders with the suggested batch size and set num_workers=0\n",
    "    train_loader_hpo = DataLoader(BookRatingsDataset(train_data, is_train=True), batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader_hpo = DataLoader(BookRatingsDataset(val_data, is_train=True), batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Initialize the model with the suggested embedding size\n",
    "    model_hpo = MatrixFactorization(num_users, num_books, embedding_size=emb_size, dropout_rate=0.1)\n",
    "    model_hpo = model_hpo.to(device)\n",
    "\n",
    "    # Define loss function and optimizer with the suggested learning rate\n",
    "    criterion_hpo = nn.MSELoss()\n",
    "    optimizer_hpo = optim.Adam(model_hpo.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    # Training parameters\n",
    "    epochs_hpo = 100\n",
    "    patience_hpo = 10\n",
    "\n",
    "    # Initialize Early Stopping variables\n",
    "    best_val_loss_hpo = float('inf')\n",
    "    patience_counter_hpo = 0\n",
    "\n",
    "    for epoch in range(1, epochs_hpo + 1):\n",
    "        model_hpo.train()\n",
    "        train_losses_hpo = []\n",
    "\n",
    "        for user, book, rating in train_loader_hpo:\n",
    "            user = user.to(device)\n",
    "            book = book.to(device)\n",
    "            rating = rating.to(device)\n",
    "\n",
    "            optimizer_hpo.zero_grad()\n",
    "            outputs = model_hpo(user, book)\n",
    "            loss = criterion_hpo(outputs, rating)\n",
    "            loss.backward()\n",
    "            optimizer_hpo.step()\n",
    "\n",
    "            train_losses_hpo.append(loss.item())\n",
    "\n",
    "        avg_train_loss_hpo = np.mean(train_losses_hpo)\n",
    "\n",
    "        # Validation Phase\n",
    "        model_hpo.eval()\n",
    "        val_losses_hpo = []\n",
    "        with torch.no_grad():\n",
    "            for user, book, rating in val_loader_hpo:\n",
    "                user = user.to(device)\n",
    "                book = book.to(device)\n",
    "                rating = rating.to(device)\n",
    "\n",
    "                outputs = model_hpo(user, book)\n",
    "                loss = criterion_hpo(outputs, rating)\n",
    "                val_losses_hpo.append(loss.item())\n",
    "\n",
    "        avg_val_loss_hpo = np.mean(val_losses_hpo)\n",
    "\n",
    "        # Early Stopping Check\n",
    "        if avg_val_loss_hpo < best_val_loss_hpo:\n",
    "            best_val_loss_hpo = avg_val_loss_hpo\n",
    "            patience_counter_hpo = 0\n",
    "            # Save the best model for this trial\n",
    "            torch.save(model_hpo.state_dict(), 'best_model_hpo.pth')\n",
    "        else:\n",
    "            patience_counter_hpo += 1\n",
    "            if patience_counter_hpo >= patience_hpo:\n",
    "                break  # Early stopping\n",
    "\n",
    "    return best_val_loss_hpo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-09 11:57:39,153] A new study created in memory with name: no-name-9de22257-b6cd-4081-b1ec-f6f0a5d3c453\n",
      "[I 2024-12-09 11:58:54,314] Trial 0 finished with value: 0.7312820383480617 and parameters: {'embedding_size': 122, 'learning_rate': 0.007969454818643935, 'batch_size': 1664}. Best is trial 0 with value: 0.7312820383480617.\n",
      "[I 2024-12-09 12:02:39,201] Trial 1 finished with value: 1.6670062116214208 and parameters: {'embedding_size': 150, 'learning_rate': 0.0002051338263087451, 'batch_size': 768}. Best is trial 0 with value: 0.7312820383480617.\n",
      "[I 2024-12-09 12:03:59,138] Trial 2 finished with value: 0.7219854518771172 and parameters: {'embedding_size': 82, 'learning_rate': 0.005399484409787433, 'batch_size': 1408}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:06:15,655] Trial 3 finished with value: 5.384723949432373 and parameters: {'embedding_size': 164, 'learning_rate': 0.00010994335574766199, 'batch_size': 2048}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:10:34,845] Trial 4 finished with value: 1.2165225744247437 and parameters: {'embedding_size': 179, 'learning_rate': 0.00026587543983272726, 'batch_size': 768}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:12:55,188] Trial 5 finished with value: 1.5068301260471344 and parameters: {'embedding_size': 98, 'learning_rate': 0.0004059611610484307, 'batch_size': 1280}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:15:20,446] Trial 6 finished with value: 1.8247417211532593 and parameters: {'embedding_size': 129, 'learning_rate': 0.0003823475224675188, 'batch_size': 1408}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:17:47,861] Trial 7 finished with value: 1.1814269542694091 and parameters: {'embedding_size': 92, 'learning_rate': 0.0003839629299804173, 'batch_size': 1024}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:19:34,041] Trial 8 finished with value: 0.7426751383713314 and parameters: {'embedding_size': 132, 'learning_rate': 0.0037183641805732083, 'batch_size': 768}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:22:32,515] Trial 9 finished with value: 0.7486709177494049 and parameters: {'embedding_size': 139, 'learning_rate': 0.0015304852121831476, 'batch_size': 512}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:24:25,048] Trial 10 finished with value: 0.8039631346861521 and parameters: {'embedding_size': 77, 'learning_rate': 0.0014572280240219713, 'batch_size': 1792}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:25:19,494] Trial 11 finished with value: 0.7339701311928886 and parameters: {'embedding_size': 108, 'learning_rate': 0.009552896679671545, 'batch_size': 1536}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:26:21,961] Trial 12 finished with value: 0.7313210538455418 and parameters: {'embedding_size': 116, 'learning_rate': 0.009364316221509938, 'batch_size': 1664}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:28:15,007] Trial 13 finished with value: 0.7286845246950785 and parameters: {'embedding_size': 75, 'learning_rate': 0.0035582742135695823, 'batch_size': 1920}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:30:04,940] Trial 14 finished with value: 0.7458695054054261 and parameters: {'embedding_size': 77, 'learning_rate': 0.0030651812172979766, 'batch_size': 2048}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:31:49,961] Trial 15 finished with value: 0.7436793910132514 and parameters: {'embedding_size': 98, 'learning_rate': 0.003355922777030417, 'batch_size': 1152}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:33:33,730] Trial 16 finished with value: 0.7288320163885752 and parameters: {'embedding_size': 75, 'learning_rate': 0.004314226186842815, 'batch_size': 1920}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:36:40,231] Trial 17 finished with value: 0.8598512038588524 and parameters: {'embedding_size': 199, 'learning_rate': 0.0008657857585898337, 'batch_size': 1408}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:38:38,788] Trial 18 finished with value: 0.7566503485043844 and parameters: {'embedding_size': 89, 'learning_rate': 0.001991736331763557, 'batch_size': 1792}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:39:52,864] Trial 19 finished with value: 0.7422508001327515 and parameters: {'embedding_size': 103, 'learning_rate': 0.005128166183551097, 'batch_size': 1152}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:41:57,312] Trial 20 finished with value: 1.1383628674915858 and parameters: {'embedding_size': 88, 'learning_rate': 0.0006821018330793578, 'batch_size': 1536}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:43:22,626] Trial 21 finished with value: 0.7272549470265707 and parameters: {'embedding_size': 79, 'learning_rate': 0.005524500049271181, 'batch_size': 1920}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:44:36,823] Trial 22 finished with value: 0.7235819200674692 and parameters: {'embedding_size': 86, 'learning_rate': 0.00643630228139967, 'batch_size': 1920}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:45:55,929] Trial 23 finished with value: 0.7420449554920197 and parameters: {'embedding_size': 87, 'learning_rate': 0.0055929442154467445, 'batch_size': 1792}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:47:55,864] Trial 24 finished with value: 0.7536853790283203 and parameters: {'embedding_size': 112, 'learning_rate': 0.00236134622453064, 'batch_size': 2048}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:49:07,078] Trial 25 finished with value: 0.7357094543320792 and parameters: {'embedding_size': 86, 'learning_rate': 0.006282181983111432, 'batch_size': 1664}. Best is trial 2 with value: 0.7219854518771172.\n",
      "[I 2024-12-09 12:50:28,424] Trial 26 finished with value: 0.7192975580692291 and parameters: {'embedding_size': 102, 'learning_rate': 0.006741575866890092, 'batch_size': 1920}. Best is trial 26 with value: 0.7192975580692291.\n",
      "[I 2024-12-09 12:51:36,904] Trial 27 finished with value: 0.7379444496972221 and parameters: {'embedding_size': 104, 'learning_rate': 0.00680143445159914, 'batch_size': 1536}. Best is trial 26 with value: 0.7192975580692291.\n",
      "[I 2024-12-09 12:53:56,989] Trial 28 finished with value: 0.7483111321926117 and parameters: {'embedding_size': 122, 'learning_rate': 0.0023424497468936237, 'batch_size': 1024}. Best is trial 26 with value: 0.7192975580692291.\n",
      "[I 2024-12-09 12:54:53,349] Trial 29 finished with value: 0.7323166813169207 and parameters: {'embedding_size': 96, 'learning_rate': 0.008129062919206887, 'batch_size': 1664}. Best is trial 26 with value: 0.7192975580692291.\n",
      "[I 2024-12-09 12:56:00,138] Trial 30 finished with value: 0.7181636542081833 and parameters: {'embedding_size': 115, 'learning_rate': 0.0070212818459619184, 'batch_size': 1408}. Best is trial 30 with value: 0.7181636542081833.\n",
      "[I 2024-12-09 12:57:13,052] Trial 31 finished with value: 0.7186588868498802 and parameters: {'embedding_size': 115, 'learning_rate': 0.006815131503946303, 'batch_size': 1408}. Best is trial 30 with value: 0.7181636542081833.\n",
      "[I 2024-12-09 12:58:44,601] Trial 32 finished with value: 0.7411821857094765 and parameters: {'embedding_size': 119, 'learning_rate': 0.004455175817739445, 'batch_size': 1280}. Best is trial 30 with value: 0.7181636542081833.\n",
      "[I 2024-12-09 12:59:46,293] Trial 33 finished with value: 0.714960440993309 and parameters: {'embedding_size': 145, 'learning_rate': 0.009968354230012818, 'batch_size': 1408}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:00:55,264] Trial 34 finished with value: 0.7402095645666122 and parameters: {'embedding_size': 149, 'learning_rate': 0.007704118434985093, 'batch_size': 1280}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:02:11,707] Trial 35 finished with value: 0.7380365398195055 and parameters: {'embedding_size': 145, 'learning_rate': 0.008228373154806096, 'batch_size': 1152}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:05:00,696] Trial 36 finished with value: 3.323661148548126 and parameters: {'embedding_size': 159, 'learning_rate': 0.00015147749198726182, 'batch_size': 1408}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:06:07,947] Trial 37 finished with value: 0.7306490490833918 and parameters: {'embedding_size': 133, 'learning_rate': 0.009750281727262868, 'batch_size': 896}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:08:27,447] Trial 38 finished with value: 0.7204379439353943 and parameters: {'embedding_size': 126, 'learning_rate': 0.0026488077280501965, 'batch_size': 1408}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:10:18,306] Trial 39 finished with value: 0.7371242983000619 and parameters: {'embedding_size': 163, 'learning_rate': 0.0044018680294217955, 'batch_size': 1536}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:13:27,477] Trial 40 finished with value: 0.7424810051918029 and parameters: {'embedding_size': 178, 'learning_rate': 0.00182855063083418, 'batch_size': 1024}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:15:33,879] Trial 41 finished with value: 0.7190876975655556 and parameters: {'embedding_size': 140, 'learning_rate': 0.0029480653673222526, 'batch_size': 1408}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:16:50,871] Trial 42 finished with value: 0.7379328683018684 and parameters: {'embedding_size': 140, 'learning_rate': 0.007044179303951141, 'batch_size': 1280}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:18:33,719] Trial 43 finished with value: 0.7357686672891889 and parameters: {'embedding_size': 154, 'learning_rate': 0.004750862951507934, 'batch_size': 1536}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:21:13,856] Trial 44 finished with value: 0.7720702812075615 and parameters: {'embedding_size': 127, 'learning_rate': 0.0010960168620342662, 'batch_size': 1280}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:23:04,204] Trial 45 finished with value: 0.7232764139771461 and parameters: {'embedding_size': 113, 'learning_rate': 0.0038058446458587984, 'batch_size': 1408}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:24:35,041] Trial 46 finished with value: 0.7458887659013271 and parameters: {'embedding_size': 137, 'learning_rate': 0.0058560682592217585, 'batch_size': 640}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:25:55,534] Trial 47 finished with value: 0.72381648847035 and parameters: {'embedding_size': 171, 'learning_rate': 0.00965810154777159, 'batch_size': 1664}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:27:55,904] Trial 48 finished with value: 0.7446229590309991 and parameters: {'embedding_size': 107, 'learning_rate': 0.003096769821007579, 'batch_size': 1152}. Best is trial 33 with value: 0.714960440993309.\n",
      "[I 2024-12-09 13:29:17,608] Trial 49 finished with value: 0.7368639186024666 and parameters: {'embedding_size': 146, 'learning_rate': 0.00704468447852406, 'batch_size': 1280}. Best is trial 33 with value: 0.714960440993309.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials:  50\n",
      "Best trial:\n",
      "  Value: 0.714960440993309\n",
      "  Params: \n",
      "    embedding_size: 145\n",
      "    learning_rate: 0.009968354230012818\n",
      "    batch_size: 1408\n"
     ]
    }
   ],
   "source": [
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n",
    "\n",
    "# Optimize the objective function\n",
    "study.optimize(objective, n_trials=50, timeout=None)  # Adjust n_trials as needed\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize optimization history\n",
    "optuna.visualization.plot_optimization_history(study)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize parameter importances\n",
    "optuna.visualization.plot_param_importances(study)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['optuna_study.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the study\n",
    "joblib.dump(study, 'optuna_study.pkl')\n",
    "\n",
    "# To load the study later\n",
    "# study = joblib.load('optuna_study.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:\n",
      "Embedding Size: 145\n",
      "Learning Rate: 0.009968354230012818\n",
      "Batch Size: 1408\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "\n",
    "\n",
    "# Extract best hyperparameters\n",
    "best_embedding_size = int(trial.params['embedding_size'])\n",
    "best_learning_rate = trial.params['learning_rate']\n",
    "best_batch_size = int(trial.params['batch_size'])\n",
    "\n",
    "print(f\"Best Hyperparameters:\\nEmbedding Size: {best_embedding_size}\\nLearning Rate: {best_learning_rate}\\nBatch Size: {best_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders with the best batch size and set num_workers=0\n",
    "train_loader_best = DataLoader(BookRatingsDataset(train_data, is_train=True), batch_size=best_batch_size, shuffle=True, num_workers=0)\n",
    "val_loader_best = DataLoader(BookRatingsDataset(val_data, is_train=True), batch_size=best_batch_size, shuffle=False, num_workers=0)\n",
    "test_loader_best = DataLoader(BookRatingsDataset(test_df, is_train=False), batch_size=best_batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the final model with best embedding size\n",
    "final_model = MatrixFactorization(num_users, num_books, embedding_size=best_embedding_size, dropout_rate=0.1)\n",
    "final_model = final_model.to(device)\n",
    "\n",
    "# Define loss function and optimizer with best learning rate\n",
    "criterion_final = nn.MSELoss()\n",
    "optimizer_final = optim.Adam(final_model.parameters(), lr=best_learning_rate, weight_decay=1e-5)\n",
    "\n",
    "# Training parameters\n",
    "epochs_final = 100\n",
    "patience_final = 10\n",
    "\n",
    "# Initialize Early Stopping variables\n",
    "best_val_loss_final = float('inf')\n",
    "patience_counter_final = 0\n",
    "\n",
    "# Initialize recent_logs for logging\n",
    "recent_logs_final = []\n",
    "max_logs_final = 5  # Maximum number of logs to display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss = 0.3820, Validation Loss = 0.7202\n",
      "Epoch 35: Train Loss = 0.3815, Validation Loss = 0.7218\n",
      "Epoch 36: Train Loss = 0.3927, Validation Loss = 0.7202\n",
      "Epoch 37: Train Loss = 0.3854, Validation Loss = 0.7239\n",
      "Epoch 38: Train Loss = 0.3908, Validation Loss = 0.7219\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs_final + 1):\n",
    "    final_model.train()\n",
    "    train_losses_final = []\n",
    "\n",
    "    for user, book, rating in tqdm(train_loader_best, desc=f\"Epoch {epoch}/{epochs_final} - Training\"):\n",
    "        user = user.to(device)\n",
    "        book = book.to(device)\n",
    "        rating = rating.to(device)\n",
    "\n",
    "        optimizer_final.zero_grad()\n",
    "        outputs = final_model(user, book)\n",
    "        loss = criterion_final(outputs, rating)\n",
    "        loss.backward()\n",
    "        optimizer_final.step()\n",
    "\n",
    "        train_losses_final.append(loss.item())\n",
    "\n",
    "    avg_train_loss_final = np.mean(train_losses_final)\n",
    "\n",
    "    # Validation Phase\n",
    "    final_model.eval()\n",
    "    val_losses_final = []\n",
    "    with torch.no_grad():\n",
    "        for user, book, rating in tqdm(val_loader_best, desc=f\"Epoch {epoch}/{epochs_final} - Validation\"):\n",
    "            user = user.to(device)\n",
    "            book = book.to(device)\n",
    "            rating = rating.to(device)\n",
    "\n",
    "            outputs = final_model(user, book)\n",
    "            loss = criterion_final(outputs, rating)\n",
    "            val_losses_final.append(loss.item())\n",
    "\n",
    "    avg_val_loss_final = np.mean(val_losses_final)\n",
    "\n",
    "    # Logging\n",
    "    log_message_final = f\"Epoch {epoch}: Train Loss = {avg_train_loss_final:.4f}, Validation Loss = {avg_val_loss_final:.4f}\"\n",
    "    recent_logs_final.append(log_message_final)\n",
    "    if len(recent_logs_final) > max_logs_final:\n",
    "        recent_logs_final.pop(0)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(\"\\n\".join(recent_logs_final))\n",
    "\n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss_final < best_val_loss_final:\n",
    "        best_val_loss_final = avg_val_loss_final\n",
    "        patience_counter_final = 0\n",
    "        # Save the best model\n",
    "        torch.save(final_model.state_dict(), 'best_final_model.pth')\n",
    "    else:\n",
    "        patience_counter_final += 1\n",
    "        if patience_counter_final >= patience_final:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "final_model.load_state_dict(torch.load('best_final_model.pth'))\n",
    "final_model = final_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate RMSE\n",
    "def calculate_rmse(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for user, book, rating in data_loader:\n",
    "            user = user.to(device)\n",
    "            book = book.to(device)\n",
    "            outputs = model(user, book)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(rating.numpy())\n",
    "    mse = mean_squared_error(actuals, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "# Define function to calculate MAE\n",
    "def calculate_mae(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for user, book, rating in data_loader:\n",
    "            user = user.to(device)\n",
    "            book = book.to(device)\n",
    "            outputs = model(user, book)\n",
    "            predictions.extend(outputs.cpu().numpy())\n",
    "            actuals.extend(rating.numpy())\n",
    "    mae = mean_absolute_error(actuals, predictions)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.8595\n",
      "Validation MAE: 0.6718\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE and MAE on validation set\n",
    "val_rmse = calculate_rmse(final_model, val_loader_best)\n",
    "val_mae = calculate_mae(final_model, val_loader_best)\n",
    "\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "print(f\"Validation MAE: {val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate predictions for test set\n",
    "def generate_test_predictions(model, data_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    ids = []\n",
    "    with torch.no_grad():\n",
    "        for id_batch, user, book in tqdm(data_loader, desc=\"Generating Predictions\"):\n",
    "            user = user.to(device)\n",
    "            book = book.to(device)\n",
    "            outputs = model(user, book)\n",
    "            preds = outputs.cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            ids.extend(id_batch.numpy())\n",
    "    return ids, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df088548d374824948dab3ad83c504c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Predictions:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "test_ids, test_predictions = generate_test_predictions(final_model, test_loader_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.210467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.919093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.469288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.478331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.343541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    rating\n",
       "0   0  2.210467\n",
       "1   1  1.919093\n",
       "2   2  1.469288\n",
       "3   3  2.478331\n",
       "4   4  2.343541"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'rating': test_predictions\n",
    "})\n",
    "\n",
    "# Ensure ratings are within the 1.0 to 5.0 range\n",
    "submission_df['rating'] = submission_df['rating'].clip(1.0, 5.0)\n",
    "\n",
    "# Display the first few predictions\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file 'submission.csv' has been created.\n"
     ]
    }
   ],
   "source": [
    "# Save the submission file\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file 'submission.csv' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dis-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
