{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-16T14:00:30.118824Z","iopub.status.busy":"2024-10-16T14:00:30.118381Z","iopub.status.idle":"2024-10-16T14:00:31.373357Z","shell.execute_reply":"2024-10-16T14:00:31.371795Z","shell.execute_reply.started":"2024-10-16T14:00:30.118774Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T14:00:35.786711Z","iopub.status.busy":"2024-10-16T14:00:35.786138Z","iopub.status.idle":"2024-10-16T14:02:15.319485Z","shell.execute_reply":"2024-10-16T14:02:15.318359Z","shell.execute_reply.started":"2024-10-16T14:00:35.786668Z"},"trusted":true},"outputs":[],"source":["import json\n","json_path = \"corpus.json\"\n","with open(json_path,\"r\",encoding='utf-8') as file:\n","    data = json.load(file)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-15T17:03:37.776811Z","iopub.status.busy":"2024-10-15T17:03:37.776274Z","iopub.status.idle":"2024-10-15T17:03:37.815813Z","shell.execute_reply":"2024-10-15T17:03:37.814296Z","shell.execute_reply.started":"2024-10-15T17:03:37.776765Z"},"trusted":true},"outputs":[],"source":["test_file_path = \"test.csv\"\n","df_test = pd.read_csv(test_file_path)"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T14:02:15.322455Z","iopub.status.busy":"2024-10-16T14:02:15.321949Z","iopub.status.idle":"2024-10-16T14:02:15.346184Z","shell.execute_reply":"2024-10-16T14:02:15.345017Z","shell.execute_reply.started":"2024-10-16T14:02:15.322398Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     /Users/martinlebras/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import fasttext\n","import re\n","import collections\n","import string\n","from num2words import num2words\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","import json\n","from tqdm import tqdm\n","import gc"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["def create_language_corpus(corpus: list) -> dict:\n","    language_corpus = {\"en\":[],\"fr\":[],\"es\":[],\"de\":[],\"it\":[],\"ar\":[],\"ko\":[]}\n","    for document in corpus:\n","        language_corpus[document[\"lang\"]].append(document)\n","    for language in tqdm(language_corpus.keys()):\n","        with open(f\"corpus_{language}.json\",\"w\",encoding='utf-8') as file:\n","            json.dump(language_corpus[language],file,ensure_ascii=False)\n","    del language_corpus"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def lowercase_sentence_start(text):\n","\n","    def lowercase_match(match):\n","        return match.group(1) + match.group(2).lower()\n","    \n","    pattern = r'([.!?]\\s+|^)([A-Z])'\n","    \n","    return re.sub(pattern, lowercase_match, text)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def convert_numbers_to_words(text, lang='en'):\n","    \n","    def replace_number(match):\n","        number_str = match.group(0)\n","        \n","        if '.' in number_str:\n","            return num2words(float(number_str), lang=lang)\n","        else:\n","            return num2words(int(number_str), lang=lang)\n","        \n","    pattern = r'\\b\\d+(\\.\\d+)?\\b'\n","    \n","    # Substitute all matched numbers with their word equivalents\n","    return re.sub(pattern, replace_number, text)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def remove_stopwords(text, lang='english'):\n","\n","    try:\n","        stop_words = set(stopwords.words(lang))\n","    except:\n","        stop_words = set()\n","    word_tokens = word_tokenize(text)\n","    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n","    \n","    return filtered_text"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-15T17:20:51.059562Z","iopub.status.busy":"2024-10-15T17:20:51.059024Z","iopub.status.idle":"2024-10-15T17:20:51.066148Z","shell.execute_reply":"2024-10-15T17:20:51.064744Z","shell.execute_reply.started":"2024-10-15T17:20:51.059515Z"},"trusted":true},"outputs":[],"source":["def preprocess_document(text: str, lower: bool, stopwords: bool, number: bool, language: str): #lower, remove punctuation and stopwords in the given language, convert numbers to their text value, handle names with captial letters\n","    language_mapping = {\"en\":\"english\",\"fr\":\"french\",\"de\":\"german\",\"es\":\"spanish\",\"ar\":\"arabic\",\"ko\":\"korean\",\"it\":\"italian\"}\n","    if lower:\n","        text = lowercase_sentence_start(text)\n","    else:\n","        text = text.lower()\n","    if number:\n","        text = convert_numbers_to_words(text, language)\n","    pattern = f\"[{re.escape(string.punctuation)}]\"\n","    text = re.sub(pattern, '', text)\n","    if stopwords:\n","        words = remove_stopwords(text,language_mapping[language])\n","    else:\n","        words = text.split(\" \")\n","    return words"]},{"cell_type":"markdown","metadata":{},"source":["Model embedding per language\n","Issue for query across languages \n","Multilingual model or consider most relevant documents are the one with same languages ? Check train data\n","Sentence embedding with TF-IDF in the document (?) and then regular aggregation across sentences of the document (min,max,mean ?)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def get_document_vocabulary(words: str) -> dict:\n","    return dict(collections.Counter(words))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["def get_corpus_frequencies(corpus: list, language: str) -> dict:\n","    corpus_dict = {}\n","    for document in tqdm(corpus):\n","        corpus_dict[document[\"docid\"]] = get_document_vocabulary(preprocess_document(document[\"text\"],False,True,False,language))\n","    return corpus_dict"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["def get_corpus_vocabulary(corpus_frequencies: dict) -> list:\n","    vocabulary = list()\n","    for doc_id in tqdm(corpus_frequencies.keys()):\n","        document_vocabulary = list(corpus_frequencies[doc_id].keys())\n","        vocabulary.extend(document_vocabulary)\n","    return list(set(vocabulary))"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["def term_frequency(word: str, document_vocabulary: dict) -> float:\n","    return document_vocabulary[word] / max(document_vocabulary.values())"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["def inverse_document_frequency(corpus_frequencies: dict, corpus_vocabulary: list) -> dict:\n","\n","    document_count_per_word = collections.defaultdict(int)\n","    \n","    for doc_id, word_freq in corpus_frequencies.items():\n","        for word in word_freq.keys():\n","            document_count_per_word[word] += 1\n","    \n","    num_documents = len(corpus_frequencies)\n","    \n","    idf = {}\n","    for word in tqdm(corpus_vocabulary):\n","        n_word = document_count_per_word[word]\n","        idf[word] = float(np.log(num_documents / n_word))\n","    \n","    return idf"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-16T14:19:14.808489Z","iopub.status.busy":"2024-10-16T14:19:14.807341Z","iopub.status.idle":"2024-10-16T14:19:14.820206Z","shell.execute_reply":"2024-10-16T14:19:14.818441Z","shell.execute_reply.started":"2024-10-16T14:19:14.808429Z"},"trusted":true},"outputs":[],"source":["def tf_idf(word: str, document_vocabulary: dict, idf: dict) -> float:\n","    return term_frequency(word, document_vocabulary)*idf[word]"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def tf_idf_mean_agg(model, document_vocabulary: dict, idf: dict) -> np.array: #Consider a weight normalization step if necessary\n","    first_word = True\n","    weights = 0\n","    for word in document_vocabulary.keys():\n","        word_embedding = model.get_word_vector(word)\n","        if first_word:\n","            document_embedding = np.zeros_like(word_embedding)\n","            first_word = False\n","        weight = tf_idf(word, document_vocabulary, idf)\n","        document_embedding += word_embedding*weight\n","        weights += weight\n","    document_embedding = document_embedding/weights\n","    return document_embedding\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["def mean_agg(model, document_vocabulary: dict) -> np.array: #Consider a weight normalization step if necessary\n","    first_word = True\n","    count = 0\n","    for word in document_vocabulary.keys():\n","        word_embedding = model.get_word_vector(word)\n","        if first_word:\n","            document_embedding = np.zeros_like(word_embedding)\n","            first_word = False\n","        document_embedding += word_embedding\n","        count += 1\n","    document_embedding = document_embedding/count\n","    return document_embedding"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["def embed_corpus(corpus: list, model, language: str, freq: bool) -> dict:\n","    documents_embeddings = {}\n","    if freq:\n","        corpus_frequencies = get_corpus_frequencies(corpus, language)\n","        corpus_vocabulary = get_corpus_vocabulary(corpus_frequencies)\n","        idf = inverse_document_frequency(corpus_frequencies, corpus_vocabulary)\n","        with open(f\"corpus_freq_{language}.json\",\"w\",encoding='utf-8') as freq_file:\n","            json.dump(corpus_frequencies, freq_file, ensure_ascii=False)\n","        with open(f\"corpus_vocab_{language}.json\",\"w\",encoding='utf-8') as vocab_file:\n","            json.dump(corpus_vocabulary, vocab_file, ensure_ascii=False)\n","        with open(f\"corpus_idf_{language}.json\",\"w\",encoding='utf-8') as idf_file:\n","            json.dump(idf, idf_file, ensure_ascii=False)\n","    else:\n","        with open(f\"corpus_idf_{language}.json\",\"r\",encoding='utf-8') as idf_file:\n","            idf = json.load(idf_file)\n","    print(f\"Embedding documents in {language}\")\n","    for document in tqdm(corpus):\n","        document_vocabulary = get_document_vocabulary(preprocess_document(document[\"text\"],False,True,False,language))\n","        documents_embeddings[document[\"docid\"]] = tf_idf_mean_agg(model, document_vocabulary, idf).tolist()\n","    print(f\"Documents embedded in {language}\")\n","    return documents_embeddings"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["def cosine_similarity(word_a: np.array, word_b: np.array) -> float:\n","    sumxx, sumxy, sumyy = 0, 0, 0\n","    for i in range(len(word_a)):\n","        x = word_a[i]; y = word_b[i]\n","        sumxx += x*x\n","        sumyy += y*y\n","        sumxy += x*y\n","    if sumxy == 0:\n","        result = 0\n","    else:\n","        result =  sumxy / np.sqrt(sumxx*sumyy)\n","    return result"]},{"cell_type":"markdown","metadata":{},"source":["Check for titles in the documents and if there is one, handle it differently\n","\n","Create a separate corpus for each language in order to have a separate vocabulary for each language"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading corpus in en\n","Corpus loaded in en\n","Loading model in en\n","Model loaded in en\n","Embedding corpus in en\n","Embedding documents in en\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 207363/207363 [43:31<00:00, 79.39it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Documents embedded in en\n","Corpus embedded in en\n","Saving embedded corpus in en\n","Embedded corpus saved in en\n","Loading corpus in fr\n","Corpus loaded in fr\n","Loading model in fr\n","Model loaded in fr\n","Embedding corpus in fr\n","Embedding documents in fr\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10676/10676 [07:06<00:00, 25.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Documents embedded in fr\n","Corpus embedded in fr\n","Saving embedded corpus in fr\n","Embedded corpus saved in fr\n","Loading corpus in it\n","Corpus loaded in it\n","Loading model in it\n","Model loaded in it\n","Embedding corpus in it\n","Embedding documents in it\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 11250/11250 [07:59<00:00, 23.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Documents embedded in it\n","Corpus embedded in it\n","Saving embedded corpus in it\n","Embedded corpus saved in it\n","Loading corpus in es\n","Corpus loaded in es\n","Loading model in es\n","Model loaded in es\n","Embedding corpus in es\n","Embedding documents in es\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 11019/11019 [07:16<00:00, 25.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Documents embedded in es\n","Corpus embedded in es\n","Saving embedded corpus in es\n","Embedded corpus saved in es\n","Loading corpus in de\n","Corpus loaded in de\n","Loading model in de\n","Model loaded in de\n","Embedding corpus in de\n","Embedding documents in de\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10992/10992 [06:53<00:00, 26.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Documents embedded in de\n","Corpus embedded in de\n","Saving embedded corpus in de\n","Embedded corpus saved in de\n","Loading corpus in ar\n","Corpus loaded in ar\n","Loading model in ar\n","Model loaded in ar\n","Embedding corpus in ar\n","Embedding documents in ar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 8829/8829 [07:48<00:00, 18.85it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Documents embedded in ar\n","Corpus embedded in ar\n","Saving embedded corpus in ar\n","Embedded corpus saved in ar\n","Loading corpus in ko\n","Corpus loaded in ko\n","Loading model in ko\n","Model loaded in ko\n","Embedding corpus in ko\n","Embedding documents in ko\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 7893/7893 [05:34<00:00, 23.59it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Documents embedded in ko\n","Corpus embedded in ko\n","Saving embedded corpus in ko\n","Embedded corpus saved in ko\n"]}],"source":["#print(\"Creating corpus for each language\")\n","#create_language_corpus(data)\n","#print(\"Corpus created for each language\")\n","#gc.collect()\n","languages = [\"en\",\"fr\",\"it\",\"es\",\"de\",\"ar\",\"ko\"]\n","for language in languages:\n","    print(f\"Loading corpus in {language}\")\n","    with open(f\"corpus_{language}.json\",\"r\",encoding='utf-8') as corpus_file:\n","        corpus = json.load(corpus_file)\n","    print(f\"Corpus loaded in {language}\")\n","\n","    print(f\"Loading model in {language}\")\n","    model = fasttext.load_model(f\"cc.{language}.300.bin\")\n","    print(f\"Model loaded in {language}\")\n","\n","    print(f\"Embedding corpus in {language}\")\n","    embedded_corpus = embed_corpus(corpus, model, language, False)\n","    print(f\"Corpus embedded in {language}\")\n","\n","    print(f\"Saving embedded corpus in {language}\")\n","    with open(f\"embedded_corpus_{language}.json\",\"w\",encoding='utf-8') as file:\n","        json.dump(embedded_corpus, file, ensure_ascii=False)\n","    print(f\"Embedded corpus saved in {language}\")\n","    del corpus, model, embedded_corpus\n","    gc.collect()\n"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["train_file_path = \"train.csv\"\n","df_train = pd.read_csv(train_file_path)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>query_id</th>\n","      <th>query</th>\n","      <th>positive_docs</th>\n","      <th>negative_docs</th>\n","      <th>lang</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>q-en-425512</td>\n","      <td>What is the connection between AAA and Lucha U...</td>\n","      <td>doc-en-798457</td>\n","      <td>['doc-en-810925', 'doc-en-634020', 'doc-en-143...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>q-en-16636</td>\n","      <td>What is the medical use of iloperidone?</td>\n","      <td>doc-en-121692</td>\n","      <td>['doc-en-177976', 'doc-en-700330', 'doc-en-567...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>q-en-282671</td>\n","      <td>Who was the provisional administrator in 1940?</td>\n","      <td>doc-en-750259</td>\n","      <td>['doc-en-805362', 'doc-en-413387', 'doc-en-827...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>q-en-216614</td>\n","      <td>What was the critical reception of the film se...</td>\n","      <td>doc-en-703883</td>\n","      <td>['doc-en-685958', 'doc-en-84060', 'doc-en-2046...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>q-en-156120</td>\n","      <td>What was the main Spanish record of the year i...</td>\n","      <td>doc-en-648393</td>\n","      <td>['doc-en-4307', 'doc-en-761696', 'doc-en-79426...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21870</th>\n","      <td>q-ar-1187</td>\n","      <td>احتفالية تلعب دورًا كبيرًا في تعزيز الترابط ال...</td>\n","      <td>doc-ar-8463</td>\n","      <td>['doc-ar-5304', 'doc-ar-1977', 'doc-ar-5843', ...</td>\n","      <td>ar</td>\n","    </tr>\n","    <tr>\n","      <th>21871</th>\n","      <td>q-ar-1188</td>\n","      <td>ما هو عدد أتباع كنيسة الأدفنتست في جزيرة سان ا...</td>\n","      <td>doc-ar-8469</td>\n","      <td>['doc-ar-6798', 'doc-ar-1489', 'doc-ar-3100', ...</td>\n","      <td>ar</td>\n","    </tr>\n","    <tr>\n","      <th>21872</th>\n","      <td>q-ar-1189</td>\n","      <td>من هو أنتاناس سمتا؟</td>\n","      <td>doc-ar-8476</td>\n","      <td>['doc-ar-2898', 'doc-ar-6787', 'doc-ar-3235', ...</td>\n","      <td>ar</td>\n","    </tr>\n","    <tr>\n","      <th>21873</th>\n","      <td>q-ar-1191</td>\n","      <td>سؤالي هو: ما هي الميزة التي كانت للإيرلنديين ف...</td>\n","      <td>doc-ar-8491</td>\n","      <td>['doc-ar-786', 'doc-ar-8084', 'doc-ar-3208', '...</td>\n","      <td>ar</td>\n","    </tr>\n","    <tr>\n","      <th>21874</th>\n","      <td>q-ar-1193</td>\n","      <td>من استحوذ على مجمع ساسكاتشوان للقمح عام 2007؟</td>\n","      <td>doc-ar-8506</td>\n","      <td>['doc-ar-2044', 'doc-ar-2480', 'doc-ar-115', '...</td>\n","      <td>ar</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21875 rows × 5 columns</p>\n","</div>"],"text/plain":["          query_id                                              query  \\\n","0      q-en-425512  What is the connection between AAA and Lucha U...   \n","1       q-en-16636            What is the medical use of iloperidone?   \n","2      q-en-282671     Who was the provisional administrator in 1940?   \n","3      q-en-216614  What was the critical reception of the film se...   \n","4      q-en-156120  What was the main Spanish record of the year i...   \n","...            ...                                                ...   \n","21870    q-ar-1187  احتفالية تلعب دورًا كبيرًا في تعزيز الترابط ال...   \n","21871    q-ar-1188  ما هو عدد أتباع كنيسة الأدفنتست في جزيرة سان ا...   \n","21872    q-ar-1189                                من هو أنتاناس سمتا؟   \n","21873    q-ar-1191  سؤالي هو: ما هي الميزة التي كانت للإيرلنديين ف...   \n","21874    q-ar-1193      من استحوذ على مجمع ساسكاتشوان للقمح عام 2007؟   \n","\n","       positive_docs                                      negative_docs lang  \n","0      doc-en-798457  ['doc-en-810925', 'doc-en-634020', 'doc-en-143...   en  \n","1      doc-en-121692  ['doc-en-177976', 'doc-en-700330', 'doc-en-567...   en  \n","2      doc-en-750259  ['doc-en-805362', 'doc-en-413387', 'doc-en-827...   en  \n","3      doc-en-703883  ['doc-en-685958', 'doc-en-84060', 'doc-en-2046...   en  \n","4      doc-en-648393  ['doc-en-4307', 'doc-en-761696', 'doc-en-79426...   en  \n","...              ...                                                ...  ...  \n","21870    doc-ar-8463  ['doc-ar-5304', 'doc-ar-1977', 'doc-ar-5843', ...   ar  \n","21871    doc-ar-8469  ['doc-ar-6798', 'doc-ar-1489', 'doc-ar-3100', ...   ar  \n","21872    doc-ar-8476  ['doc-ar-2898', 'doc-ar-6787', 'doc-ar-3235', ...   ar  \n","21873    doc-ar-8491  ['doc-ar-786', 'doc-ar-8084', 'doc-ar-3208', '...   ar  \n","21874    doc-ar-8506  ['doc-ar-2044', 'doc-ar-2480', 'doc-ar-115', '...   ar  \n","\n","[21875 rows x 5 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["df_train"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["languages = [\"en\",\"fr\",\"es\",\"it\",\"de\",\"ar\",\"ko\"]\n","corpus_query = {language:df_train[df_train[\"lang\"] == language][[\"query_id\",\"query\"]].set_index(\"query_id\").to_dict()[\"query\"] for language in languages}"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def embed_queries(corpus: dict, model, language: str, freq: bool) -> dict:\n","    queries_embeddings = {}\n","    with open(f\"corpus_idf_{language}.json\",\"r\",encoding='utf-8') as idf_file:\n","        idf = json.load(idf_file)\n","    print(f\"Embedding queries in {language}\")\n","    for query_id, query_text in tqdm(corpus.items()):\n","        query_vocabulary = get_document_vocabulary(preprocess_document(query_text,False,True,False,language))\n","        try:\n","            queries_embeddings[query_id] = mean_agg(model, query_vocabulary).tolist()\n","        except:\n","            print(query_id)\n","            print(query_text)\n","    print(f\"Documents queries in {language}\")\n","    return queries_embeddings"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading corpus in en\n","Corpus loaded in en\n","Loading model in en\n","Model loaded in en\n","Embedding corpus in en\n","Embedding queries in en\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 10000/10000 [00:01<00:00, 7965.68it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Documents queries in en\n","Corpus embedded in en\n","Saving embedded corpus in en\n","Embedded corpus saved in en\n","Loading corpus in fr\n","Corpus loaded in fr\n","Loading model in fr\n","Model loaded in fr\n","Embedding corpus in fr\n","Embedding queries in fr\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1608/1608 [00:00<00:00, 5724.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Documents queries in fr\n","Corpus embedded in fr\n","Saving embedded corpus in fr\n","Embedded corpus saved in fr\n","Loading corpus in it\n","Corpus loaded in it\n","Loading model in it\n","Model loaded in it\n","Embedding corpus in it\n","Embedding queries in it\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2151/2151 [00:00<00:00, 5826.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["q-it-867\n","chi?\n","Documents queries in it\n","Corpus embedded in it\n","Saving embedded corpus in it\n","Embedded corpus saved in it\n","Loading corpus in es\n","Corpus loaded in es\n","Loading model in es\n","Model loaded in es\n","Embedding corpus in es\n","Embedding queries in es\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2254/2254 [00:00<00:00, 5189.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Documents queries in es\n","Corpus embedded in es\n","Saving embedded corpus in es\n","Embedded corpus saved in es\n","Loading corpus in de\n","Corpus loaded in de\n","Loading model in de\n","Model loaded in de\n","Embedding corpus in de\n","Embedding queries in de\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1847/1847 [00:00<00:00, 5369.70it/s]"]},{"name":"stdout","output_type":"stream","text":["q-de-484\n","sein könnte. \n","Documents queries in de\n","Corpus embedded in de\n","Saving embedded corpus in de\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Embedded corpus saved in de\n","Loading corpus in ar\n","Corpus loaded in ar\n","Loading model in ar\n","Model loaded in ar\n","Embedding corpus in ar\n","Embedding queries in ar\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1817/1817 [00:00<00:00, 4433.72it/s]"]},{"name":"stdout","output_type":"stream","text":["q-ar-414\n","أيلول.\n","Documents queries in ar\n","Corpus embedded in ar\n","Saving embedded corpus in ar\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Embedded corpus saved in ar\n","Loading corpus in ko\n","Corpus loaded in ko\n","Loading model in ko\n","Model loaded in ko\n","Embedding corpus in ko\n","Embedding queries in ko\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2198/2198 [00:00<00:00, 7429.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Documents queries in ko\n","Corpus embedded in ko\n","Saving embedded corpus in ko\n","Embedded corpus saved in ko\n"]}],"source":["languages = [\"en\",\"fr\",\"it\",\"es\",\"de\",\"ar\",\"ko\"]\n","for language in languages:\n","    print(f\"Loading corpus in {language}\")\n","    corpus = corpus_query[language]\n","    print(f\"Corpus loaded in {language}\")\n","\n","    print(f\"Loading model in {language}\")\n","    model = fasttext.load_model(f\"cc.{language}.300.bin\")\n","    print(f\"Model loaded in {language}\")\n","\n","    print(f\"Embedding corpus in {language}\")\n","    embedded_queries = embed_queries(corpus, model, language, False)\n","    print(f\"Corpus embedded in {language}\")\n","\n","    print(f\"Saving embedded corpus in {language}\")\n","    with open(f\"embedded_queries_{language}.json\",\"w\",encoding='utf-8') as file:\n","        json.dump(embedded_queries, file, ensure_ascii=False)\n","    print(f\"Embedded corpus saved in {language}\")\n","    del corpus, model, embedded_queries\n","    gc.collect()"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["def find_top_k_doc(queries,documents,k,language):\n","    query_matrix = list()\n","    queries_ids = list()\n","    for query_id, query_embeddings in queries.items():\n","        query_matrix.append(query_embeddings)\n","        queries_ids.append(query_id)\n","    query_matrix = np.array(query_matrix)\n","    queries_norms = np.diagonal(query_matrix.dot(query_matrix.T))\n","    queries_inverse_norms = np.linalg.inv(np.diag(np.sqrt(queries_norms)))\n","    \n","    doc_matrix = list()\n","    doc_ids = list()\n","    for doc_id, doc_embeddings in documents.items():\n","        doc_matrix.append(doc_embeddings)\n","        doc_ids.append(doc_id)\n","\n","    if language != \"en\":\n","        doc_matrix = np.array(doc_matrix)\n","        documents_norms = np.diagonal(doc_matrix.dot(doc_matrix.T))\n","        documents_inverse_norms = np.linalg.inv(np.diag(np.sqrt(documents_norms)))\n","        cosine_similarities = np.dot(queries_inverse_norms,np.dot(np.dot(query_matrix,doc_matrix.T),documents_inverse_norms))\n","    else:\n","        step = len(doc_matrix)//10\n","        cosine_similarities = np.zeros((len(queries_ids),len(doc_ids)))\n","        for i in range(10):\n","            if i != 9:\n","                doc_sub_matrix = np.array(doc_matrix[i*step:(i+1)*step])\n","            else:\n","                doc_sub_matrix = np.array(doc_matrix[i*step:])\n","            documents_norms = np.diagonal(doc_sub_matrix.dot(doc_sub_matrix.T))\n","            documents_inverse_norms = np.linalg.inv(np.diag(np.sqrt(documents_norms)))\n","            sub_cosine_similarities = np.dot(queries_inverse_norms,np.dot(np.dot(query_matrix,doc_sub_matrix.T),documents_inverse_norms))\n","            if i != 9:\n","                cosine_similarities[:,i*step:(i+1)*step] = sub_cosine_similarities\n","            else:\n","                cosine_similarities[:,i*step:] = sub_cosine_similarities\n","    top_k_per_query = cosine_similarities.argsort(axis=1)[::-1][:,:k]\n","    doc_ids = np.array(doc_ids)\n","    top_k_documents_id = dict()\n","    for i in range(len(queries_ids)):\n","        top_k_documents_id[queries_ids[i]] = doc_ids[top_k_per_query[i]].tolist()\n","    return top_k_documents_id"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["languages = [\"en\",\"fr\",\"es\",\"de\",\"ar\",\"ko\",\"it\"]\n","for language in languages:\n","    with open(f\"embedded_corpus_{language}.json\",\"r\",encoding='utf-8') as doc_file:\n","        corpus = json.load(doc_file)\n","    with open(f\"embedded_queries_{language}.json\",\"r\",encoding='utf-8') as query_file:\n","        queries = json.load(query_file)\n","    retrieved_documents = find_top_k_doc(queries,corpus,10,language)\n","    with open(f\"retrieved_doc_{language}.json\",\"w\",encoding='utf-8') as output_file:\n","        json.dump(retrieved_documents,output_file,ensure_ascii=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Write an evaluation code for the current doc retrieval"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["with open(f\"retrieved_doc_en.json\",\"r\",encoding=\"utf-8\") as retrieved_file:\n","    data = json.load(retrieved_file)"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["df = pd.DataFrame(data)"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["df = df.transpose().reset_index()"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>q-en-425512</td>\n","      <td>doc-en-683410</td>\n","      <td>doc-en-87691</td>\n","      <td>doc-en-2392</td>\n","      <td>doc-en-567893</td>\n","      <td>doc-en-449096</td>\n","      <td>doc-en-120949</td>\n","      <td>doc-en-523773</td>\n","      <td>doc-en-377963</td>\n","      <td>doc-en-11048</td>\n","      <td>doc-en-729127</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>q-en-16636</td>\n","      <td>doc-en-11272</td>\n","      <td>doc-en-817826</td>\n","      <td>doc-en-414492</td>\n","      <td>doc-en-156581</td>\n","      <td>doc-en-577807</td>\n","      <td>doc-en-482496</td>\n","      <td>doc-en-654818</td>\n","      <td>doc-en-680868</td>\n","      <td>doc-en-784770</td>\n","      <td>doc-en-740422</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>q-en-282671</td>\n","      <td>doc-en-822640</td>\n","      <td>doc-en-766157</td>\n","      <td>doc-en-608311</td>\n","      <td>doc-en-683410</td>\n","      <td>doc-en-787714</td>\n","      <td>doc-en-567893</td>\n","      <td>doc-en-789308</td>\n","      <td>doc-en-2392</td>\n","      <td>doc-en-87691</td>\n","      <td>doc-en-449096</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>q-en-216614</td>\n","      <td>doc-en-617596</td>\n","      <td>doc-en-207868</td>\n","      <td>doc-en-261720</td>\n","      <td>doc-en-317333</td>\n","      <td>doc-en-784948</td>\n","      <td>doc-en-190</td>\n","      <td>doc-en-11016</td>\n","      <td>doc-en-654980</td>\n","      <td>doc-en-474411</td>\n","      <td>doc-en-675837</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>q-en-156120</td>\n","      <td>doc-en-238769</td>\n","      <td>doc-en-482496</td>\n","      <td>doc-en-685577</td>\n","      <td>doc-en-630923</td>\n","      <td>doc-en-3944</td>\n","      <td>doc-en-626695</td>\n","      <td>doc-en-201419</td>\n","      <td>doc-en-740422</td>\n","      <td>doc-en-273450</td>\n","      <td>doc-en-742864</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>q-en-491</td>\n","      <td>doc-en-11016</td>\n","      <td>doc-en-784948</td>\n","      <td>doc-en-675837</td>\n","      <td>doc-en-697014</td>\n","      <td>doc-en-654980</td>\n","      <td>doc-en-647534</td>\n","      <td>doc-en-261720</td>\n","      <td>doc-en-641059</td>\n","      <td>doc-en-586849</td>\n","      <td>doc-en-249064</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>q-en-3689</td>\n","      <td>doc-en-711877</td>\n","      <td>doc-en-675837</td>\n","      <td>doc-en-781613</td>\n","      <td>doc-en-784722</td>\n","      <td>doc-en-484904</td>\n","      <td>doc-en-11016</td>\n","      <td>doc-en-662348</td>\n","      <td>doc-en-828072</td>\n","      <td>doc-en-784948</td>\n","      <td>doc-en-601460</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>q-en-82165</td>\n","      <td>doc-en-136137</td>\n","      <td>doc-en-400917</td>\n","      <td>doc-en-206058</td>\n","      <td>doc-en-792979</td>\n","      <td>doc-en-666061</td>\n","      <td>doc-en-784689</td>\n","      <td>doc-en-237360</td>\n","      <td>doc-en-289130</td>\n","      <td>doc-en-832700</td>\n","      <td>doc-en-399850</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>q-en-157794</td>\n","      <td>doc-en-457559</td>\n","      <td>doc-en-524615</td>\n","      <td>doc-en-583706</td>\n","      <td>doc-en-797081</td>\n","      <td>doc-en-824865</td>\n","      <td>doc-en-14628</td>\n","      <td>doc-en-816276</td>\n","      <td>doc-en-1309</td>\n","      <td>doc-en-808912</td>\n","      <td>doc-en-14625</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>q-en-421489</td>\n","      <td>doc-en-11272</td>\n","      <td>doc-en-817826</td>\n","      <td>doc-en-414492</td>\n","      <td>doc-en-833116</td>\n","      <td>doc-en-673178</td>\n","      <td>doc-en-784770</td>\n","      <td>doc-en-703109</td>\n","      <td>doc-en-453036</td>\n","      <td>doc-en-740422</td>\n","      <td>doc-en-795904</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows × 11 columns</p>\n","</div>"],"text/plain":["            index              0              1              2              3  \\\n","0     q-en-425512  doc-en-683410   doc-en-87691    doc-en-2392  doc-en-567893   \n","1      q-en-16636   doc-en-11272  doc-en-817826  doc-en-414492  doc-en-156581   \n","2     q-en-282671  doc-en-822640  doc-en-766157  doc-en-608311  doc-en-683410   \n","3     q-en-216614  doc-en-617596  doc-en-207868  doc-en-261720  doc-en-317333   \n","4     q-en-156120  doc-en-238769  doc-en-482496  doc-en-685577  doc-en-630923   \n","...           ...            ...            ...            ...            ...   \n","9995     q-en-491   doc-en-11016  doc-en-784948  doc-en-675837  doc-en-697014   \n","9996    q-en-3689  doc-en-711877  doc-en-675837  doc-en-781613  doc-en-784722   \n","9997   q-en-82165  doc-en-136137  doc-en-400917  doc-en-206058  doc-en-792979   \n","9998  q-en-157794  doc-en-457559  doc-en-524615  doc-en-583706  doc-en-797081   \n","9999  q-en-421489   doc-en-11272  doc-en-817826  doc-en-414492  doc-en-833116   \n","\n","                  4              5              6              7  \\\n","0     doc-en-449096  doc-en-120949  doc-en-523773  doc-en-377963   \n","1     doc-en-577807  doc-en-482496  doc-en-654818  doc-en-680868   \n","2     doc-en-787714  doc-en-567893  doc-en-789308    doc-en-2392   \n","3     doc-en-784948     doc-en-190   doc-en-11016  doc-en-654980   \n","4       doc-en-3944  doc-en-626695  doc-en-201419  doc-en-740422   \n","...             ...            ...            ...            ...   \n","9995  doc-en-654980  doc-en-647534  doc-en-261720  doc-en-641059   \n","9996  doc-en-484904   doc-en-11016  doc-en-662348  doc-en-828072   \n","9997  doc-en-666061  doc-en-784689  doc-en-237360  doc-en-289130   \n","9998  doc-en-824865   doc-en-14628  doc-en-816276    doc-en-1309   \n","9999  doc-en-673178  doc-en-784770  doc-en-703109  doc-en-453036   \n","\n","                  8              9  \n","0      doc-en-11048  doc-en-729127  \n","1     doc-en-784770  doc-en-740422  \n","2      doc-en-87691  doc-en-449096  \n","3     doc-en-474411  doc-en-675837  \n","4     doc-en-273450  doc-en-742864  \n","...             ...            ...  \n","9995  doc-en-586849  doc-en-249064  \n","9996  doc-en-784948  doc-en-601460  \n","9997  doc-en-832700  doc-en-399850  \n","9998  doc-en-808912   doc-en-14625  \n","9999  doc-en-740422  doc-en-795904  \n","\n","[10000 rows x 11 columns]"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>query_id</th>\n","      <th>query</th>\n","      <th>positive_docs</th>\n","      <th>negative_docs</th>\n","      <th>lang</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>q-en-425512</td>\n","      <td>What is the connection between AAA and Lucha U...</td>\n","      <td>doc-en-798457</td>\n","      <td>['doc-en-810925', 'doc-en-634020', 'doc-en-143...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>q-en-16636</td>\n","      <td>What is the medical use of iloperidone?</td>\n","      <td>doc-en-121692</td>\n","      <td>['doc-en-177976', 'doc-en-700330', 'doc-en-567...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>q-en-282671</td>\n","      <td>Who was the provisional administrator in 1940?</td>\n","      <td>doc-en-750259</td>\n","      <td>['doc-en-805362', 'doc-en-413387', 'doc-en-827...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>q-en-216614</td>\n","      <td>What was the critical reception of the film se...</td>\n","      <td>doc-en-703883</td>\n","      <td>['doc-en-685958', 'doc-en-84060', 'doc-en-2046...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>q-en-156120</td>\n","      <td>What was the main Spanish record of the year i...</td>\n","      <td>doc-en-648393</td>\n","      <td>['doc-en-4307', 'doc-en-761696', 'doc-en-79426...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>q-en-491</td>\n","      <td>What is the title of the book written by Śrī M...</td>\n","      <td>doc-en-3808</td>\n","      <td>['doc-en-598746', 'doc-en-638512', 'doc-en-417...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>q-en-3689</td>\n","      <td>the 1983 World Championships, he was still not...</td>\n","      <td>doc-en-26598</td>\n","      <td>['doc-en-344827', 'doc-en-313792', 'doc-en-248...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>q-en-82165</td>\n","      <td>What common characteristics did the investigat...</td>\n","      <td>doc-en-442441</td>\n","      <td>['doc-en-692064', 'doc-en-741970', 'doc-en-140...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>q-en-157794</td>\n","      <td>What are the limitations of the LAV III's grou...</td>\n","      <td>doc-en-653407</td>\n","      <td>['doc-en-709748', 'doc-en-631594', 'doc-en-602...</td>\n","      <td>en</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>q-en-421489</td>\n","      <td>What did the person argue about the representa...</td>\n","      <td>doc-en-788430</td>\n","      <td>['doc-en-312410', 'doc-en-511694', 'doc-en-447...</td>\n","      <td>en</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows × 5 columns</p>\n","</div>"],"text/plain":["         query_id                                              query  \\\n","0     q-en-425512  What is the connection between AAA and Lucha U...   \n","1      q-en-16636            What is the medical use of iloperidone?   \n","2     q-en-282671     Who was the provisional administrator in 1940?   \n","3     q-en-216614  What was the critical reception of the film se...   \n","4     q-en-156120  What was the main Spanish record of the year i...   \n","...           ...                                                ...   \n","9995     q-en-491  What is the title of the book written by Śrī M...   \n","9996    q-en-3689  the 1983 World Championships, he was still not...   \n","9997   q-en-82165  What common characteristics did the investigat...   \n","9998  q-en-157794  What are the limitations of the LAV III's grou...   \n","9999  q-en-421489  What did the person argue about the representa...   \n","\n","      positive_docs                                      negative_docs lang  \n","0     doc-en-798457  ['doc-en-810925', 'doc-en-634020', 'doc-en-143...   en  \n","1     doc-en-121692  ['doc-en-177976', 'doc-en-700330', 'doc-en-567...   en  \n","2     doc-en-750259  ['doc-en-805362', 'doc-en-413387', 'doc-en-827...   en  \n","3     doc-en-703883  ['doc-en-685958', 'doc-en-84060', 'doc-en-2046...   en  \n","4     doc-en-648393  ['doc-en-4307', 'doc-en-761696', 'doc-en-79426...   en  \n","...             ...                                                ...  ...  \n","9995    doc-en-3808  ['doc-en-598746', 'doc-en-638512', 'doc-en-417...   en  \n","9996   doc-en-26598  ['doc-en-344827', 'doc-en-313792', 'doc-en-248...   en  \n","9997  doc-en-442441  ['doc-en-692064', 'doc-en-741970', 'doc-en-140...   en  \n","9998  doc-en-653407  ['doc-en-709748', 'doc-en-631594', 'doc-en-602...   en  \n","9999  doc-en-788430  ['doc-en-312410', 'doc-en-511694', 'doc-en-447...   en  \n","\n","[10000 rows x 5 columns]"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["df_train_language"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["evaluation_df = df_train_language.merge(df,left_on=\"query_id\",right_on=\"index\",how=\"inner\",suffixes=['','_retrieved'])"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"data":{"text/plain":["0       doc-en-798457\n","1       doc-en-121692\n","2       doc-en-750259\n","3       doc-en-703883\n","4       doc-en-648393\n","            ...      \n","9995      doc-en-3808\n","9996     doc-en-26598\n","9997    doc-en-442441\n","9998    doc-en-653407\n","9999    doc-en-788430\n","Name: positive_docs, Length: 10000, dtype: object"]},"execution_count":87,"metadata":{},"output_type":"execute_result"}],"source":["evaluation_df[\"positive_docs\"]"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[{"data":{"text/plain":["0       0\n","1       0\n","2       0\n","3       0\n","4       0\n","       ..\n","9995    0\n","9996    0\n","9997    0\n","9998    0\n","9999    0\n","Length: 10000, dtype: int64"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["((evaluation_df[\"positive_docs\"] == evaluation_df[0]) | (evaluation_df[\"positive_docs\"] == evaluation_df[1]) | (evaluation_df[\"positive_docs\"] == evaluation_df[2]) | (evaluation_df[\"positive_docs\"] == evaluation_df[3]) | (evaluation_df[\"positive_docs\"] == evaluation_df[4]) | (evaluation_df[\"positive_docs\"] == evaluation_df[5]) | (evaluation_df[\"positive_docs\"] == evaluation_df[6]) | (evaluation_df[\"positive_docs\"] == evaluation_df[7]) | (evaluation_df[\"positive_docs\"] == evaluation_df[8]) | (evaluation_df[\"positive_docs\"] == evaluation_df[9])).astype(int)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["evaluation_df[\"retrieved\"] = evaluation_df[\"retrieved\"].str.split(\", \")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for language in languages:\n","    df_train_language = df_train[df_train[\"lang\"] == language]\n","    with open(f\"retrieved_doc_{language}.json\",\"r\",encoding=\"utf-8\") as retrieved_file:\n","        data = json.load(retrieved_file)\n","    df = pd.DataFrame(data)\n","    df = df.transpose().reset_index()\n","    df[\"retrieved\"] = df.apply(lambda x: x[0] + \", \" + x[1] + \", \" + x[2] + \", \" + x[3] + \", \" + x[4] + \", \" + x[5] + \", \" + x[6] + \", \" + x[7] + \", \" + x[8] + \", \" + x[9],axis=1)\n","    evaluation_df = df_train_language.merge(df[[\"index\",\"retrieved\"]],left_on=\"query_id\",right_on=\"index\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Look for embedding combination strategies"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9635715,"sourceId":85316,"sourceType":"competition"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"}},"nbformat":4,"nbformat_minor":4}
